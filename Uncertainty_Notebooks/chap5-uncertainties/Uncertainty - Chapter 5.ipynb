{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type A Evaluations of Uncertainy\n",
    "\n",
    "In previous chapters you have come to understand what a measurement is, and how to use a probability density function to model your information about a measurand. The pdf may be summarised by your best approximation of the measurand and the standard uncertainty, which together form the result of the measurement.\n",
    "\n",
    "You have already learnt how to complete a Type B evaluation of uncertainty to estimate the standard uncertainty associated with certain sources of uncertainty. In this chapter you will learn how to deal with dispersion (scatter) in a set of repeated readings (observations) of the same measurand.\n",
    "\n",
    "\n",
    "## 5.1 Dispersion of Data\n",
    "\n",
    "Consider the following experiment being performed by yourself in the physics laboratory. A wooden slope is clamped near the edge of a table. A ball is released from a height h above the table as shown in the diagram. The ball leaves the slope __horizontally__ and lands on the floor a distance d from the edge of the table. Special paper is placed on the floor on which the ball makes a small mark when it lands and you use a long ruler to measure d and h . You have been asked to investigate how the distance d on the floor changes when the height h is varied.\n",
    "\n",
    "\n",
    "<img src=\"5_1-Fig1.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "You decide to roll the ball once from a height h = 78.0 mm. You then see a single spot on the paper where the ball landed.  The first thing to do is to measure d with a ruler. Since the ruler has markings every 1 mm, we can estimate the reading of d to the nearest 0.1 mm.\n",
    "\n",
    "<img src=\"5_1-Fig2.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "What value would you record for the location of this spot, d_1 in millimeters?  Enter your answer in the cell below.  Hit <kbd>Shift</kbd>+<kbd>Enter</kbd> after entering your value.\n",
    "\n",
    "<kbd>Shift</kbd>+<kbd>Enter</kbd> tells the notebook to evaluate the code in the cell.  In this case it will assign your numerical value to the variable d_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You think that d_1 is equal to 650.5 mm.\n"
     ]
    }
   ],
   "source": [
    "d_1= 650.5 #Enter your number in millimeters after the equals sign on this line\n",
    "\n",
    "print(\"You think that d_1 is equal to\", d_1, \"mm.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You decide to roll the ball a second time from the same height h = 78.0 mm and observe that the ball lands at a slightly different position. You now see two spots on the paper.\n",
    "\n",
    "<img src=\"5_1-Fig3.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "What value would you record for d_2?  Enter your value in the cell below.  Hit <kbd>Shift</kbd>+<kbd>Enter</kbd> after entering your value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_2=  #Enter your number after the equals sign on this line\n",
    "\n",
    "print(\"You think that d_2 is equal to\", d_2, \"mm.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What should you write down if you were asked to record one value to represent the best value for the distance d?  You can do arithmetic in code cells.  For instance, if you thought that you should subtract the two values of d_1 and d_2 and then multiply that result by 113 (clearly you are a little confused) to calculate the best value for d, you could type the following into the cell below:\n",
    "\n",
    "```python\n",
    "\n",
    "d=113*(d_1-d_2)\n",
    "```\n",
    "\n",
    "Enter your value for d below and explain why you chose this value by replacing the text between quotes. Hit <kbd>Shift</kbd>+<kbd>Enter</kbd> after entering your value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d=   #Enter your number after the equals sign on this line\n",
    "\n",
    "print(\"You think the best value to describe d is\",d,\"mm.\")\n",
    "\n",
    "print(\"Enter your answer to the question between these quote signs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say that you now decide to roll the ball a third time from the same height h = 78.0 mm, and the ball lands at a slightly different position. You now see three spots on the paper.\n",
    "\n",
    "<img src=\"5_1-Fig4.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "Write down your value for d_3.  Also, include what value you would record for the best value of d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_3 =  #Enter your number after the equals sign on this line\n",
    "\n",
    "print(\"You think that d_3 is equal to\", d_3, \"mm.\")\n",
    "\n",
    "d =  #Enter your number after the equals sign on this line\n",
    "\n",
    "print(\"You think the best value for d is\",d,\"mm.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is clearly a dispersion, or scatter, in the readings for d. Why do all the spots not occur exactly on top of each other?  Actually, it is usually not possible to identify a single reason for what causes the observed scatter in the data. Even if you do the experiment as carefully as possible, then there will still be a dispersion in the readings of d. The important question is how to deal with this dispersion (in this case d).\n",
    "\n",
    "The best approximation for d after one roll is clearly 650.4 mm. After 2 or more rolls, the average, or arithmetic mean, of all the readings is usually the best value to use. Why is this the case ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Enter your answer here between the quote signs and replace this text.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You take a fourth measurement and find that d_4=669.6 mm.  \n",
    "\n",
    "Put your cursor in the following cell and hit <kbd>Shift</kbd> + <kbd>Enter</kbd>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_4=666.9\n",
    "\n",
    "print(\"After 2 measurements the average is d=\",(d_1+d_2)/2,\"mm.\")\n",
    "\n",
    "print(\"After 3 measurements the average is d=\",(d_1+d_2+d_3)/3,\"mm.\")\n",
    "\n",
    "print(\"After 4 measurements the average is d=\",(d_1+d_2+d_3+d_4)/4,\"mm.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the average changes as we take more and more readings.\n",
    "\n",
    "<img src=\"5_1-Fig5.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "It is not possible to give a firm answer to this question. Let us say that you decide to roll the ball a total of 75 times from the same height, h = 78.0 mm. Then you might see the following pattern of spots on the paper:\n",
    "\n",
    "<img src=\"5_1-Fig6.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "Look at the table on the next page. The data from Table 5.1 are listed together with the “running average”, which is the average calculated up to and including each reading. You can see that the average jumps around quite a bit when there are only a few readings. As the number of readings increases, the average approaches a constant value.\n",
    "Therefore when you see a dispersion in your readings in an experiment, then you should try to take as many readings as possible. Of course, it is usually not practical to take millions of readings, but you need to carefully consider how many repeated readings are necessary to give a reliable average.\n",
    "\n",
    "We will use Python and a Python package called pandas (which stands for **Pa**nel **Da**ta **S**et) to import and analyze the data to help us answer the question about how much data we need.\n",
    "\n",
    "The first thing we need to do is tell Python to import the pandas functions and then import our data.\n",
    "\n",
    "Don't forget that you need to hit <kbd>Shift</kbd> + <kbd>Enter</kbd> to run the code cells.\n",
    "\n",
    "---\n",
    "\n",
    "Note: If you are running this on your laptop, make sure the file 'data_for_uncertainty_packet_1.csv' is in the same folder as this notebook.  \n",
    "\n",
    "If you are running this on Google Colab, you'll need to comment/uncomment lines below.  Put a hashtag in front of the line `data=pd.read...` and remove the comment hashtags from the two lines below it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "#Used to show plots and graphs in the notebook\n",
    "\n",
    "import pandas as pd  #Import all of the function in pandas\n",
    "\n",
    "### Comment out the line below if using Google Colab\n",
    "data=pd.read_csv('data_for_uncertainty_packet_1.csv')   #Read in the data file\n",
    "\n",
    "#url = 'https://raw.githubusercontent.com/zimmermant/spring_2022_139-439/main/Uncertainty_Notebooks/chap5-uncertainties/data_for_uncertainty_packet_1.csv'\n",
    "#data = pd.read_csv(url)\n",
    "### Uncomment the two lines above if using Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assigned the set of data (called a dataframe) the name ```data``` (because we clearly lack imagination ;).  To look at the data we have just imported we can just type the name we assigned to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measurements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>599.808197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>661.222745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>662.578944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>691.993904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>670.920782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>696.048456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>671.238760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>693.148831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>690.893400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>679.470112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>671.372211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>682.820053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>637.044886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>649.236465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>646.638097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>665.141300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>651.050932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>638.585089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>661.838186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>647.561383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>642.385359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>645.129176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>656.223614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>655.867593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>620.000638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>643.164622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>673.112645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>649.569723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>690.723448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>685.419472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>649.157326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>662.953074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>654.004890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>623.332725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>686.444732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>651.830988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>680.657572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>658.909961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>646.170201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>643.969198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>647.830595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>648.065929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>675.641202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>646.610033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>630.381697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>666.484439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>637.688874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>655.647044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>629.543362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>646.299185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>630.312974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>651.350884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>691.190356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>645.697184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>675.132914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>649.510752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>631.830688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>652.181425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>652.145342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>667.515974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    measurements\n",
       "0     599.808197\n",
       "1     661.222745\n",
       "2     662.578944\n",
       "3     691.993904\n",
       "4     670.920782\n",
       "5     696.048456\n",
       "6     671.238760\n",
       "7     693.148831\n",
       "8     690.893400\n",
       "9     679.470112\n",
       "10    671.372211\n",
       "11    682.820053\n",
       "12    637.044886\n",
       "13    649.236465\n",
       "14    646.638097\n",
       "15    665.141300\n",
       "16    651.050932\n",
       "17    638.585089\n",
       "18    661.838186\n",
       "19    647.561383\n",
       "20    642.385359\n",
       "21    645.129176\n",
       "22    656.223614\n",
       "23    655.867593\n",
       "24    620.000638\n",
       "25    643.164622\n",
       "26    673.112645\n",
       "27    649.569723\n",
       "28    690.723448\n",
       "29    685.419472\n",
       "..           ...\n",
       "45    649.157326\n",
       "46    662.953074\n",
       "47    654.004890\n",
       "48    623.332725\n",
       "49    686.444732\n",
       "50    651.830988\n",
       "51    680.657572\n",
       "52    658.909961\n",
       "53    646.170201\n",
       "54    643.969198\n",
       "55    647.830595\n",
       "56    648.065929\n",
       "57    675.641202\n",
       "58    646.610033\n",
       "59    630.381697\n",
       "60    666.484439\n",
       "61    637.688874\n",
       "62    655.647044\n",
       "63    629.543362\n",
       "64    646.299185\n",
       "65    630.312974\n",
       "66    651.350884\n",
       "67    691.190356\n",
       "68    645.697184\n",
       "69    675.132914\n",
       "70    649.510752\n",
       "71    631.830688\n",
       "72    652.181425\n",
       "73    652.145342\n",
       "74    667.515974\n",
       "\n",
       "[75 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data  #Print the data to make sure it looks ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been imported from a comma separated value file (.csv), which can be created in Excel.  The entire data set has been named ```data``` and the first data column is called ```data.measurements``` (the column name is at the top of the list in the previous cell).\n",
    "\n",
    "Look at the output from the cell below.  Don't worry about what the code means. The data are listed together with the “running average”, which is the average calculated up to and including each reading. You can see that the average jumps around quite a bit when there are only a few readings. As the number of readings increases, the average approaches a constant value.\n",
    "\n",
    "Therefore when you see a dispersion in your readings in an experiment, then you should try to take as many readings as possible. Of course, it is usually not practical to take millions of readings, but you need to carefully consider how many repeated readings are necessary to give a reliable average.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def running_average(dataframe,column):\n",
    "    new_data1=[]\n",
    "    for i in range(0,column.size):\n",
    "        new_data1.append(column[0:i+1].mean())\n",
    "    dataframe['running_avg']=pd.Series(new_data1, index=dataframe.index)\n",
    "running_average(data,data.measurements)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the table in the previous cell, decide how many rolls from h = 78.0 mm would be reasonable to give a reliable average for d. Justify your answer in the cell below.  How many values need to be averaged together before the running average starts to settle down to a single value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Enter your answer here and replace this text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also conclude from this that the more readings we take, the more confident we feel about the average, i.e. the more reliable we think that our best approximation (given by the average) will be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the data $d_1$, $d_2$, ..., $d_N$, we have seen that the best approximation of the value of d\n",
    "is given by the average, or arithmetic mean, $\\bar{d}$ of the data:\n",
    "\n",
    "$$\\bar{d} = \\frac{d_1+d_2+d_3+...+d_N}{N}$$\n",
    "\n",
    "where $d_1$ is the first distance measure in our list, $d_N$ is the Nth distance measurement, and N is the total number of readings (in this case 75).\n",
    "\n",
    "However, is this average value the whole story? What about the spread in the data? For example, compare the two sets of data shown below. The first set (Group A) is the same as discussed above. The second set of data are from another group of students (Group B) who also rolled the ball from the same height, h = 78.0 mm.\n",
    "\n",
    "<img src=\"5_1-Fig7.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "Describe in the cell below how the two data sets differ from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Enter your answer here and replace this text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Although the average of the two data sets is actually the same (653.6 mm), the data from group A are spread over a larger range than the data from group B. Which group do you think did a more careful experiment? A careful experiment leads to better data. We usually say that the better data are of a higher quality. Clearly the quality of the data from Group B is better than the quality of the data of Group A since the spread is smaller in B than for A. We therefore need some way of quantifying the spread of $d_1$, $d_2$, ..., $d_{75}$ about the mean $\\bar{d}$. This spread in the observed readings is a source of uncertainty in our knowledge about d , and you can see that the uncertainty in the measurement of Group B will be smaller than that for Group A.\n",
    "\n",
    "We already have the data $d_1$, $d_2$, ..., $d_{75}$ and so the next step is to use a suitable probability density function which will allow us to model our knowledge about the measurand d. When we have a set of readings which show a dispersion, as we have above, it is appropriate to use a Gaussian (or “normal”) probability density function to depict our knowledge about the measurand.\n",
    "\n",
    "We can convince ourselves that the Gaussian is a good choice of pdf by thinking about the following. We can group (or “bin”) our data by counting how many data readings fall within consecutive intervals of equal width. For the data we are processing, a reasonable “bin” size is 5 mm (see later below why this is the case). Therefore our bins could be 620.0 mm to 624.9 mm, 625.0 mm to 629.9 mm , 630.0 mm to 634.9 mm, etc.\n",
    "\n",
    "Look carefully at the diagram on the next page to understand what we are doing.\n",
    "\n",
    "Another way of presenting this analysis of the data is to draw up a **frequency table** (or distribution table). The middle column in Table 5.2 below lists the number of readings falling within each 5 mm - wide bin . We can then calculate the **relative frequency** for each bin, where\n",
    "\n",
    "$$Relative\\ Frequency = \\frac{The\\ number\\ of\\ readings\\ in\\ a\\ bin}{The\\ total\\ number\\ of\\ readings}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_bins=15 #Change this number to change the number of bins the data is collected in\n",
    "\n",
    "bin_count=data.measurements.value_counts(bins=number_of_bins)\n",
    "freq_table=pd.DataFrame({'frequency':bin_count.values, 'range':bin_count.index})\n",
    "freq_table['relative_freq']=freq_table.frequency/freq_table.frequency.sum()\n",
    "\n",
    "print(freq_table)\n",
    "\n",
    "print('The sum of all values in the relative_freq column is ',freq_table.relative_freq.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is useful to plot a histogram of the data to see the distribution of the data.  We expect it to look like a Gaussian distribution.  The ```.plot.hist()``` command creates a histogram of the specified column (in this case it is ```data.measurements```).  The number in parentheses specifies how many bins to place the measurements in.  At the moment the data is grouped into four ranges.  Place your cursor in the cell below and hit <kbd>Shift</kbd> + <kbd>Enter</kbd>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.measurements.plot.hist(bins=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try varying the number of bins the data is grouped in the previous cell.  Try ```data.measurements.plot.hist(10)``` to change the histogram to having 10 bins.  Also try 15, 25, and 50 bins.  Be sure to hit <kbd>Shift</kbd> + <kbd>Enter</kbd> after you change the number in parentheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagram below illustrates what we are doing if we set our bin size to 5-mm\n",
    "\n",
    "<img src=\"5_1-Fig8.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "<img src=\"5_1-Fig9.png\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relative frequency tells us the fraction of readings falling within each bin. As we take more and more readings, the histogram of relative frequencies approaches the (theoretical) probability of getting a reading between two values of d . We can overlap a Gaussian curve on top of the histogram of the relative frequencies from Table 5.2 .The more readings we have and the smaller we make our bin size, the closer the shape of the histogram of relative frequencies will approximate a smooth Gaussian distribution.\n",
    "\n",
    "<img src=\"5_1-Fig10.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "There is nothing mysterious about of choice of bin width (5 mm in this case). We could have chosen a wider or narrower bin width, if we wanted to. However, you need to choose a sensible bin width so that you can see how the data are distributed. To do this you need to look carefully at your data and consider the actual readings, as well as how many readings you have.\n",
    "\n",
    "For example, if we had chosen a bin width of 100 mm, then all the data would fall within the same 100 mm-wide bin:\n",
    "\n",
    "<img src=\"5_1-Fig11.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "If we had chosen a bin width of 10 mm, then this would have been better. However, although you can start to imagine the shape of a bell-shaped Gaussian distribution, it is not that convincing, since the bins are still too wide.\n",
    "\n",
    "<img src=\"5_1-Fig12.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "On the other hand, if we had chosen a bin width of 1 mm, this would also not be good,\n",
    "since we have too few readings to see the shape of the distribution.\n",
    "\n",
    "<img src=\"5_1-Fig13.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "A 1-mm bin width would be fine if we had many more readings. For example, if we had 200 repeated readings instead of 50, then we might see something like the distribution shown below, which again looks like a bell-shaped Gaussian:\n",
    "\n",
    "<img src=\"5_1-Fig14.png\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The experimental standard deviation of the mean\n",
    "\n",
    "A Gaussian probability density function therefore seems to be suitable choice when dealing with sets of dispersed readings (see Appendix G). We have already seen that the best approximation of the value of the measurand (d in this case) is given by arithmetic mean or average $\\bar{d}$ of the data:\n",
    "\n",
    "$$\\bar{d} = \\frac{d_1+d_2+d_3+...+d_N}{N}$$\n",
    "\n",
    " where N is the number of readings (in this case 75).\n",
    " \n",
    "For the 75 readings from our data, what is the average (or mean) value: $\\bar{d}$ = ????? mm. \n",
    "\n",
    "Type ```data.measurements.mean()``` in the cell below to find the average value of the data column.  Add a print statement that states what your average value for d is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enter your code to find the mean value below\n",
    "\n",
    "\n",
    "#Enter your code to print below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the standard uncertainty for the measurement?\n",
    "\n",
    "What we are looking for is some measure of the “average scatter” of the data, which is related the average width of the Gaussian pdf. This will be a measure of the standard uncertainty in the result. One way to get the average width of the pdf would be to take each reading $d_i$ , subtract it from $\\bar{d}$ , add them all up, and then divide by the number of readings N.\n",
    "\n",
    "Can you see what would be the result of calculating this ?\n",
    "\n",
    "In other words, $\\frac{(d_1-\\bar{d}) + (d_2 - \\bar{d}) + ... + (d_N-\\bar{d})}{N}$ = ????\n",
    "\n",
    "The result of this calculation will always be zero! Why is this the case? Think carefully! Convince yourself that this is true by using the four readings:\n",
    "d1 =650.4mm, d2 =660.6mm, d3 =659.1mm and d4 =669.6mm\n",
    "\n",
    "Calculate the average value in the cell below, along with the proposed standard deviation to show that this deviation is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore we use the square of the deviations $(d_i-\\bar{d})^2$ and calculate $\\frac{1}{N-1}\\left( (d_1-\\bar{d})^2 + (d_2 - \\bar{d})^2 + ... + (d_N - \\bar{d})^2 \\right)$\n",
    "\n",
    "This expression is called the **variance**. Note that we divide by $(N − 1)$ and not $N$ (because we are using the mean $\\bar{d}$ in the calculation). The variance gives us a measure of the spread of the data. The square root of the variance is called the **experimental standard deviation** $s(d)$,i.e.\n",
    "\n",
    "$$s(d)=\\sqrt(\\frac{1}{N-1}\\left( (d_1-\\bar{d})^2 + (d_2 - \\bar{d})^2 + ... + (d_N - \\bar{d})^2 \\right))$$\n",
    "\n",
    "This can be written more compactly as\n",
    "$$ s(d) = \\sqrt{\\frac{\\sum\\limits_{i=1}^N (d_i-\\bar{d})^2}{N-1}}$$\n",
    "\n",
    "Now we have two quantities, the average $\\bar{d}$ and the standard deviation $s(d)$, which give the best approximation of the measurand together with a measure of the spread of the data, respectively.\n",
    "\n",
    "The **standard uncertainty** associated with the dispersion in the data is given by the **experimental standard deviation of the mean** $s(\\bar{d})$ where\n",
    "\n",
    "$$s(\\bar{d}) = \\frac{s(d)}{\\sqrt{N}}$$\n",
    "\n",
    "You can see that $s (\\bar{d})$ is smaller than $s (d )$. The reason for this is quite technical, therefore all we say here is the following. The experimental standard deviation of the mean $s (\\bar{d} )$ is the average width of a Gaussian pdf which is not the Gaussian curve that appears in the figures above. What you need to imagine is repeating the experiment many times and calculating the averages of the data sets obtained from each separate repeated experiment. The distribution of all these averages will also be Gaussian in shape, and $s (\\bar{d} )$ is then related to the width of this Gaussian pdf.\n",
    "\n",
    "Calculating the standard uncertainty associated with the scatter in data, using the equations above, is called a **Type A evaluation**.\n",
    "\n",
    "There are three ways of calculating an experimental standard deviation of the mean:\n",
    "(a) using equations above (by hand) ; and\n",
    "(b) using the same formulae “buried” in the statistics functions in your scientific calculator.\n",
    "(c) using Python to do all of the heavy lifting for you\n",
    "\n",
    "To let Python do all the work, type ```data.measurements.describe()``` to see a summary of the statistics for your data.  Notice that the standard deviation given by the ```.describe()``` command is the standard deviation $s(d)$ and not the experimental standard deviation of the mean $s(\\bar{d})$.  You will need to calculate $s(\\bar{d})$ yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enter your code to get the summary of the data here\n",
    "\n",
    "\n",
    "# Once you have the standard deviation from the .describe() command, calculate the experimental standard deviation of the mean below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down the final result for your best approximation of d and the uncertainty of d in the cell below.\n",
    "\n",
    "Note that ```d_avg``` = $\\bar{d}$ and ```s_avg``` = $s(\\bar{d})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_avg =    #Enter your answer for d here\n",
    "s_avg =     #Enter your answer for s here\n",
    "\n",
    "\n",
    "print('For h = 78.0 mm, the best approximation for the distance d is', d_avg,\"mm with a standard uncertainty of\", s_avg, \"mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you will not always “see” a scatter in your repeated readings of the same measurand. Sometimes you may repeat an experiment a number of times, and all of your readings will be identical. This happens when your apparatus is not sensitive enough to display scatter in the readings. In other words, the instrument itself is putting all the readings into the same bin.\n",
    "\n",
    "When your repeated data turn out to be identical, then you can only undertake Type B evaluations of uncertainty, as if you only had a single reading. However, if your data are scattered, then you also need to calculate the uncertainty associated with the scatter using a Type A evaluation, as described in this chapter.\n",
    "\n",
    "<img src=\"5_1-Fig15.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "These students are confused since until you actually repeat the reading, you will not know whether or not it will be different from the first reading obtained. If you do observe a scatter, then you should repeat your readings many times. Calculating the average and experimental standard deviation of the mean (giving the standard uncertainty) is a way of dealing with the dispersion based on using a Gaussian pdf. This is called a **Type A evaluation** of uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
